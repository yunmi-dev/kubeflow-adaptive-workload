"""
ì „ì²´ ì‹¤í—˜ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
"""
import json
import os
import time
import numpy as np
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from src.performance_scorer import PerformanceScorer
from src.data_distributor import DataDistributor
from src.trainer import DistributedTrainer, NodeProfile
from src.optimizer import WeightOptimizer

class ExperimentRunner:
    def __init__(self):
        self.total_data = 60000
        self.scorer = PerformanceScorer()
        self.distributor = DataDistributor(self.total_data)
        
        # í•™ìŠµ ì„¤ì •
        self.model_config = {
            'batch_size': 32,
            'epochs': 3  # ì‹¤í—˜ìš© (ë¹ ë¥´ê²Œ)
        }
        
        self.trainer = DistributedTrainer(self.model_config)
        
        # ë…¸ë“œ í”„ë¡œí•„
        self.nodes = self.trainer.nodes
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        os.makedirs('results', exist_ok=True)
        os.makedirs('experiments/grid_search', exist_ok=True)
        os.makedirs('experiments/random_search', exist_ok=True)
        os.makedirs('experiments/bayesian_opt', exist_ok=True)
    
    def objective_function(self, alpha: float, beta: float, gamma: float, delta: float) -> float:
        """
        ëª©ì  í•¨ìˆ˜: ì£¼ì–´ì§„ ê°€ì¤‘ì¹˜ë¡œ JCT ê³„ì‚°
        """
        # ê° ë…¸ë“œì˜ ë©”íŠ¸ë¦­ ì‹œë®¬ë ˆì´ì…˜
        node_metrics = []
        for node in self.nodes:
            metrics = self.scorer.simulate_node_metrics(node.cpu_factor)
            node_metrics.append(metrics)
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        scores = []
        for metrics in node_metrics:
            score = self.scorer.calculate_performance_score(metrics, alpha, beta, gamma, delta)
            scores.append(score)
        
        # ë°ì´í„° ë¶„ë°°
        distributions = self.distributor.distribute_data(scores)
        
        # JCT ì¶”ì • (ì‹¤ì œ í•™ìŠµ ì—†ì´ ë¹ ë¥´ê²Œ)
        # ì‹¤ì œ ì‹œê°„ = ë°ì´í„° í¬ê¸° / ì„±ëŠ¥ ì ìˆ˜
        estimated_times = []
        for i, (dist, node) in enumerate(zip(distributions, self.nodes)):
            # ê¸°ì¤€: 1000 samplesë‹¹ 1ì´ˆ (ê³ ì„±ëŠ¥ ë…¸ë“œ ê¸°ì¤€)
            base_time = dist / 1000.0
            # CPU ì„±ëŠ¥ ë°˜ì˜
            simulated_time = base_time / node.cpu_factor
            estimated_times.append(simulated_time)
        
        jct = max(estimated_times)
        
        return jct
    
    def run_baseline_experiment(self):
        """Baseline ì‹¤í—˜: ê· ë“± ë¶„ë°°"""
        print("\n" + "="*80)
        print("ğŸ¯ Baseline ì‹¤í—˜ (ê· ë“± ë¶„ë°°)")
        print("="*80)
        
        baseline_dist = [20000, 20000, 20000]
        result = self.trainer.run_distributed_training(
            baseline_dist,
            experiment_name="Baseline (ê· ë“± ë¶„ë°°)"
        )
        
        # ì €ì¥
        with open('results/baseline.json', 'w') as f:
            json.dump(result, f, indent=2, default=self._json_converter)
        
        return result
    
    def run_simple_adaptive_experiment(self):
        """Simple Adaptive ì‹¤í—˜: ë‹¨ìˆœ ì„±ëŠ¥ ë¹„ìœ¨"""
        print("\n" + "="*80)
        print("ğŸ¯ Simple Adaptive ì‹¤í—˜ (ë‹¨ìˆœ ì„±ëŠ¥ ë¹„ìœ¨ 4:2:1)")
        print("="*80)
        
        # ì„±ëŠ¥ ë¹„ìœ¨: 1.0 : 0.5 : 0.25 = 4 : 2 : 1
        adaptive_dist = [
            int(self.total_data * 4 / 7),
            int(self.total_data * 2 / 7),
            int(self.total_data * 1 / 7)
        ]
        adaptive_dist[0] += self.total_data - sum(adaptive_dist)
        
        result = self.trainer.run_distributed_training(
            adaptive_dist,
            experiment_name="Simple Adaptive (ì„±ëŠ¥ ë¹„ìœ¨)"
        )
        
        # ì €ì¥
        with open('results/simple_adaptive.json', 'w') as f:
            json.dump(result, f, indent=2, default=self._json_converter)
        
        return result
    
    def run_optimization_experiments(self):
        """3ê°€ì§€ ìµœì í™” ê¸°ë²• ì‹¤í—˜"""
        
        optimizer = WeightOptimizer(self.objective_function)
        
        # 1. Grid Search
        print("\n" + "="*80)
        print("ğŸ” Grid Search ìµœì í™”")
        print("="*80)
        
        grid_result = optimizer.grid_search(
            alpha_range=[0.35, 0.4, 0.45, 0.5],
            beta_range=[0.2, 0.25, 0.3],
            gamma_range=[0.1, 0.15, 0.2],
            delta_constraint=(0.1, 0.2)
        )
        
        with open('experiments/grid_search/results.json', 'w') as f:
            json.dump(grid_result, f, indent=2, default=self._json_converter)
        
        # 2. Random Search
        print("\n" + "="*80)
        print("ğŸ² Random Search ìµœì í™”")
        print("="*80)
        
        random_result = optimizer.random_search(
            n_iterations=50,  # ë¹ ë¥´ê²Œ í•˜ê¸° ìœ„í•´ 50íšŒ
            alpha_range=(0.3, 0.5),
            beta_range=(0.2, 0.3),
            gamma_range=(0.1, 0.2),
            delta_constraint=(0.1, 0.2)
        )
        
        with open('experiments/random_search/results.json', 'w') as f:
            json.dump(random_result, f, indent=2, default=self._json_converter)
        
        # 3. Bayesian Optimization
        print("\n" + "="*80)
        print("ğŸ§  Bayesian Optimization ìµœì í™”")
        print("="*80)
        
        bayesian_result = optimizer.bayesian_optimization(
            n_iterations=20,  # ë¹ ë¥´ê²Œ í•˜ê¸° ìœ„í•´ 20íšŒ
            n_initial=5,
            alpha_range=(0.3, 0.5),
            beta_range=(0.2, 0.3),
            gamma_range=(0.1, 0.2),
            delta_constraint=(0.1, 0.2)
        )
        
        with open('experiments/bayesian_opt/results.json', 'w') as f:
            json.dump(bayesian_result, f, indent=2, default=self._json_converter)
        
        return {
            'grid_search': grid_result,
            'random_search': random_result,
            'bayesian_opt': bayesian_result
        }
    
    def run_final_validation(self, optimization_results):
        """ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì‹¤ì œ ë¶„ì‚° í•™ìŠµ ì‹¤í–‰"""
        
        print("\n" + "="*80)
        print("âœ… ìµœì¢… ê²€ì¦: ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì‹¤ì œ í•™ìŠµ")
        print("="*80)
        
        final_results = {}
        
        for method_name, opt_result in optimization_results.items():
            best_weights = opt_result['best_weights']
            alpha = best_weights['alpha']
            beta = best_weights['beta']
            gamma = best_weights['gamma']
            delta = best_weights['delta']
            
            print(f"\n{'='*60}")
            print(f"ë°©ë²•: {method_name}")
            print(f"ìµœì  ê°€ì¤‘ì¹˜: Î±={alpha:.3f}, Î²={beta:.3f}, Î³={gamma:.3f}, Î´={delta:.3f}")
            print(f"{'='*60}")
            
            # ë©”íŠ¸ë¦­ ì‹œë®¬ë ˆì´ì…˜
            node_metrics = []
            for node in self.nodes:
                metrics = self.scorer.simulate_node_metrics(node.cpu_factor)
                node_metrics.append(metrics)
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            scores = []
            for metrics in node_metrics:
                score = self.scorer.calculate_performance_score(metrics, alpha, beta, gamma, delta)
                scores.append(score)
            
            # ë°ì´í„° ë¶„ë°°
            distributions = self.distributor.distribute_data(scores)
            
            print(f"\në°ì´í„° ë¶„ë°°: {distributions}")
            
            # ì‹¤ì œ í•™ìŠµ
            result = self.trainer.run_distributed_training(
                distributions,
                experiment_name=f"Optimized by {method_name}"
            )
            
            final_results[method_name] = result
        
        # ì €ì¥
        with open('results/optimized_results.json', 'w') as f:
            json.dump(final_results, f, indent=2, default=self._json_converter)
        
        return final_results
    
    def generate_summary_report(self, baseline, simple_adaptive, optimized_results):
        """ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        
        print("\n" + "="*80)
        print("ğŸ“Š ìµœì¢… ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        baseline_jct = baseline['jct_simulated']
        simple_jct = simple_adaptive['jct_simulated']
        
        print(f"\n1. Baseline (ê· ë“± ë¶„ë°°)")
        print(f"   JCT: {baseline_jct:.2f}s")
        print(f"   ì‹œê°„ ê· í˜•ë„: {baseline['balance']['balance_score']:.4f}")
        
        print(f"\n2. Simple Adaptive (ì„±ëŠ¥ ë¹„ìœ¨ 4:2:1)")
        print(f"   JCT: {simple_jct:.2f}s")
        print(f"   ê°œì„ ìœ¨: {(baseline_jct - simple_jct) / baseline_jct * 100:.2f}%")
        print(f"   ì‹œê°„ ê· í˜•ë„: {simple_adaptive['balance']['balance_score']:.4f}")
        
        print(f"\n3. ìµœì í™” ê¸°ë²•ë³„ ê²°ê³¼:")
        
        summary = {
            'baseline': {
                'jct': baseline_jct,
                'balance': baseline['balance']['balance_score']
            },
            'simple_adaptive': {
                'jct': simple_jct,
                'improvement': (baseline_jct - simple_jct) / baseline_jct * 100,
                'balance': simple_adaptive['balance']['balance_score']
            },
            'optimized_methods': {}
        }
        
        for method_name, result in optimized_results.items():
            jct = result['jct_simulated']
            improvement = (baseline_jct - jct) / baseline_jct * 100
            balance = result['balance']['balance_score']
            
            print(f"\n   [{method_name}]")
            print(f"   JCT: {jct:.2f}s")
            print(f"   ê°œì„ ìœ¨: {improvement:.2f}%")
            print(f"   ì‹œê°„ ê· í˜•ë„: {balance:.4f}")
            
            summary['optimized_methods'][method_name] = {
                'jct': jct,
                'improvement': improvement,
                'balance': balance
            }
        
        # ìµœê³  ì„±ëŠ¥ ë°©ë²•
        best_method = min(optimized_results.items(), key=lambda x: x[1]['jct_simulated'])
        best_name, best_result = best_method
        best_jct = best_result['jct_simulated']
        best_improvement = (baseline_jct - best_jct) / baseline_jct * 100
        
        print(f"\n" + "="*80)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_name}")
        print(f"   JCT: {best_jct:.2f}s")
        print(f"   ì´ ê°œì„ ìœ¨: {best_improvement:.2f}%")
        print(f"   ì‹œê°„ ê· í˜•ë„: {best_result['balance']['balance_score']:.4f}")
        print("="*80)
        
        summary['best_method'] = {
            'name': best_name,
            'jct': best_jct,
            'total_improvement': best_improvement
        }
        
        # ì €ì¥
        with open('results/summary_report.json', 'w') as f:
            json.dump(summary, f, indent=2, default=self._json_converter)
        
        return summary
    
    def _json_converter(self, o):
        """JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ë³€í™˜ê¸°"""
        if isinstance(o, (np.integer, np.int64)):
            return int(o)
        if isinstance(o, (np.floating, np.float64)):
            return float(o)
        if isinstance(o, np.ndarray):
            return o.tolist()
        return str(o)

def main():
    print("="*80)
    print("ğŸš€ Kubeflow ì ì‘í˜• ì›Œí¬ë¡œë“œ ë¶„ë°° ì‹œìŠ¤í…œ - ì „ì²´ ì‹¤í—˜")
    print("="*80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    runner = ExperimentRunner()
    
    # 1. Baseline ì‹¤í—˜
    baseline = runner.run_baseline_experiment()
    
    # 2. Simple Adaptive ì‹¤í—˜
    simple_adaptive = runner.run_simple_adaptive_experiment()
    
    # 3. ìµœì í™” ì‹¤í—˜ (Grid/Random/Bayesian)
    optimization_results = runner.run_optimization_experiments()
    
    # 4. ìµœì¢… ê²€ì¦ (ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì‹¤ì œ í•™ìŠµ)
    optimized_results = runner.run_final_validation(optimization_results)
    
    # 5. ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    summary = runner.generate_summary_report(baseline, simple_adaptive, optimized_results)
    
    print(f"\n{'='*80}")
    print(f"âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: ./results/")
    print("="*80)
    
    return summary

if __name__ == "__main__":
    summary = main()